{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest Wikipedia English dump (this will take more than 4 hours)\n",
    "# ! wget \"http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text using WikiExtractor (this will take about 3 hours)\n",
    "# ! python -m wikiextractor.WikiExtractor -o \"data/wikipedia/\" --json \\\n",
    "# --filter_disambig_page \\\n",
    "# --processes 8 \\\n",
    "# \"data/enwiki-latest-pages-articles.xml.bz2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Index wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = 'localhost' \n",
    "PORT = 9200 \n",
    "INDEX_NAME = 'wikipedia_en'\n",
    "\n",
    "from haystack import Finder\n",
    "from haystack.indexing.cleaning import clean_wiki_text\n",
    "from haystack.indexing.utils import convert_files_to_dicts, fetch_archive_from_http\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.reader.transformers import TransformersReader\n",
    "from haystack.utils import print_answers\n",
    "from haystack.database.elasticsearch import ElasticsearchDocumentStore\n",
    "document_store = ElasticsearchDocumentStore(host=HOST, port=PORT, username=\"\", password=\"\", index=INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear existing index (optional)\n",
    "if document_store.client.indices.exists(index=document_store.index):\n",
    "    print('clear existing inddex')\n",
    "    document_store.client.indices.delete(index=document_store.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all dirs in wikipedia folder\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "wikidata_path = \"../data/wikipedia\"\n",
    "onlydirs = [f for f in listdir(wikidata_path) if not isfile(join(wikidata_path, f))]\n",
    "\n",
    "dicts = []\n",
    "bulk_size = 5000\n",
    "\n",
    "pbar = tqdm(onlydirs)\n",
    "for directory in pbar:\n",
    "    subdirs = [f for f in listdir(join(wikidata_path,directory)) if not isfile(join(wikidata_path,directory))]\n",
    "    pbar.set_description(f\"Processing wikipedia folder {directory}\")\n",
    "\n",
    "    for file in subdirs:\n",
    "        f = open(join(wikidata_path,directory,file), \"r\") \n",
    "        \n",
    "        # Each text file contains json structures separated by EOL\n",
    "        articles = f.read().split(\"\\n\")\n",
    "        \n",
    "        for article in articles:\n",
    "            if len(article)==0: continue\n",
    "\n",
    "            # Article in json format\n",
    "            json_formatted_article = json.loads(article)\n",
    "\n",
    "            # Rename keys\n",
    "            document = {\"id\": json_formatted_article[\"id\"],\n",
    "                        \"name\": json_formatted_article[\"title\"],\n",
    "                        \"url\": json_formatted_article[\"url\"], \n",
    "                        \"text\": json_formatted_article[\"text\"]}\n",
    "\n",
    "            # Add document to bulk\n",
    "            dicts.append(document)\n",
    "            \n",
    "            if len(dicts)>=bulk_size:\n",
    "                # Index bulk\n",
    "                try:\n",
    "                    document_store.write_documents(dicts)\n",
    "                    dicts.clear()\n",
    "                except:\n",
    "                    print(\"Bulk not indexed\")\n",
    "        \n",
    "    \n",
    "if len(dicts) > 0:\n",
    "    print('final round')\n",
    "    document_store.write_documents(dicts)\n",
    "            \n",
    "print('finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qa-venv",
   "language": "python",
   "name": "qa-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
